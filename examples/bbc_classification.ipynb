{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BBC dataset \n",
    "**Caution:** Many data valuation methods require training large number of models to get reliable estimates. **It is extremely inefficient**. We recommend using embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Opendataval\n",
    "from opendataval.dataloader import Register, DataFetcher, mix_labels, add_gauss_noise\n",
    "from opendataval.dataval.random import RandomEvaluator\n",
    "from opendataval.dataval.margcontrib import LeaveOneOut, DataShapley, BetaShapley\n",
    "from opendataval.dataval.influence import InfluenceFunctionEval\n",
    "from opendataval.dataval.dvrl import DVRL\n",
    "from opendataval.dataval.knnshap import KNNShapley\n",
    "from opendataval.dataval.margcontrib.banzhaf import DataBanzhaf\n",
    "from opendataval.dataval.ame import AME\n",
    "from opendataval.dataval.oob import DataOob\n",
    "\n",
    "from opendataval.experiment import ExperimentMediator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 1] Set up an environment\n",
    "`ExperimentMediator` is a fundamental concept in establishing the `opendataval` environment. It empowers users to configure hyperparameters, including a dataset, a type of synthetic noise, and a prediction model. With  `ExperimentMediator`, users can effortlessly compute various data valuation algorithms.\n",
    "\n",
    "The following code cell demonstrates how to set up `ExperimentMediator` with a pre-registered dataset and a prediction model.\n",
    "- Dataset: bbc\n",
    "- Model: transformer's DistilBertModel\n",
    "- Metric: Classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base line model metric_name='accuracy': perf=0.8939999938011169\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"bbc\" \n",
    "train_count, valid_count, test_count = 1000, 100, 500\n",
    "noise_rate = 0.1\n",
    "noise_kwargs = {'noise_rate': noise_rate}\n",
    "model_name = \"BertClassifier\"\n",
    "metric_name = \"accuracy\"\n",
    "train_kwargs = {\"epochs\": 2, \"batch_size\": 50}\n",
    "device = torch.device('cuda')\n",
    "\n",
    "exper_med = ExperimentMediator.model_factory_setup(\n",
    "    dataset_name=dataset_name,\n",
    "    cache_dir=\"../data_files/\",  \n",
    "    force_download=False,\n",
    "    train_count=train_count,\n",
    "    valid_count=valid_count,\n",
    "    test_count=test_count,\n",
    "    add_noise=mix_labels,\n",
    "    noise_kwargs=noise_kwargs,\n",
    "    train_kwargs=train_kwargs,\n",
    "    device=device,\n",
    "    model_name=model_name,\n",
    "    metric_name=metric_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 2] Compute data values\n",
    "`opendataval` provides various state-of-the-art data valuation algorithms. `ExperimentMediator.compute_data_values()` computes data values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_evaluators = [ \n",
    "    RandomEvaluator(),\n",
    "#     LeaveOneOut(), # leave one out ## slow\n",
    "    InfluenceFunctionEval(num_models=10), # influence function\n",
    "#     DVRL(rl_epochs=10), # Data valuation using Reinforcement Learning ## inappropriate\n",
    "#     KNNShapley(k_neighbors=valid_count), # KNN-Shapley ## inappropriate\n",
    "#     DataShapley(gr_threshold=1.05, mc_epochs=300, cache_name=f\"cached\"), # Data-Shapley ## slow\n",
    "#     BetaShapley(gr_threshold=1.05, mc_epochs=300, cache_name=f\"cached\"), # Beta-Shapley ## slow\n",
    "    DataBanzhaf(num_models=10), # Data-Banzhaf\n",
    "    AME(num_models=10), # Average Marginal Effects\n",
    "    DataOob(num_models=10) # Data-OOB\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time RandomEvaluator(): 0:00:00.026010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:18<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time InfluenceFunctionEval(num_models=10): 0:00:18.837721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:14<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time DataBanzhaf(num_models=10): 0:00:14.123893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:06<00:00,  1.52it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:11<00:00,  1.17s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:16<00:00,  1.65s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:21<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time AME(num_models=10): 0:00:56.581227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:30<00:00,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time DataOob(num_models=10): 0:00:30.067738\n",
      "CPU times: user 1min 50s, sys: 9.07 s, total: 1min 59s\n",
      "Wall time: 1min 59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# compute data values.\n",
    "## Training multiple DistilBERT models is extremely slow. We recommend using embeddings.\n",
    "exper_med = exper_med.compute_data_values(data_evaluators=data_evaluators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 3] Store data values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../tmp/bbc_noise_rate=0.1/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from opendataval.experiment.exper_methods import save_dataval\n",
    "\n",
    "# Saving the results\n",
    "output_dir = f\"../tmp/{dataset_name}_{noise_rate=}/\"\n",
    "exper_med.set_output_directory(output_dir)\n",
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indices</th>\n",
       "      <th>data_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomEvaluator()</th>\n",
       "      <td>102</td>\n",
       "      <td>0.666932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomEvaluator()</th>\n",
       "      <td>1934</td>\n",
       "      <td>0.861419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomEvaluator()</th>\n",
       "      <td>1380</td>\n",
       "      <td>0.566374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomEvaluator()</th>\n",
       "      <td>569</td>\n",
       "      <td>0.252284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomEvaluator()</th>\n",
       "      <td>1428</td>\n",
       "      <td>0.216644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DataOob(num_models=10)</th>\n",
       "      <td>1482</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DataOob(num_models=10)</th>\n",
       "      <td>1945</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DataOob(num_models=10)</th>\n",
       "      <td>2151</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DataOob(num_models=10)</th>\n",
       "      <td>813</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DataOob(num_models=10)</th>\n",
       "      <td>886</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       indices data_values\n",
       "RandomEvaluator()          102    0.666932\n",
       "RandomEvaluator()         1934    0.861419\n",
       "RandomEvaluator()         1380    0.566374\n",
       "RandomEvaluator()          569    0.252284\n",
       "RandomEvaluator()         1428    0.216644\n",
       "...                        ...         ...\n",
       "DataOob(num_models=10)    1482         1.0\n",
       "DataOob(num_models=10)    1945        0.75\n",
       "DataOob(num_models=10)    2151         1.0\n",
       "DataOob(num_models=10)     813         1.0\n",
       "DataOob(num_models=10)     886         0.8\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exper_med.evaluate(save_dataval, save_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
