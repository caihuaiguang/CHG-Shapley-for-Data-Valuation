{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BBC dataset \n",
    "**Caution:** Many data valuation methods require training large number of models to get reliable estimates. **It is extremely slow**. We recommend using embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : Cuda libraries were not detected on the system ; using cpu only mode\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Opendataval\n",
    "from opendataval.dataloader import Register, DataFetcher, mix_labels, add_gauss_noise\n",
    "from opendataval.dataval import (\n",
    "    AME,\n",
    "    DVRL,\n",
    "    BetaShapley,\n",
    "    DataBanzhaf,\n",
    "    DataOob,\n",
    "    DataShapley,\n",
    "    InfluenceSubsample,\n",
    "    KNNShapley,\n",
    "    LavaEvaluator,\n",
    "    LeaveOneOut,\n",
    "    RandomEvaluator,\n",
    "    RobustVolumeShapley,\n",
    ")\n",
    "\n",
    "from opendataval.experiment import ExperimentMediator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 1] Set up an environment\n",
    "`ExperimentMediator` is a fundamental concept in establishing the `opendataval` environment. It empowers users to configure hyperparameters, including a dataset, a type of synthetic noise, and a prediction model. With  `ExperimentMediator`, users can effortlessly compute various data valuation algorithms.\n",
    "\n",
    "The following code cell demonstrates how to set up `ExperimentMediator` with a pre-registered dataset and a prediction model.\n",
    "- Dataset: bbc\n",
    "- Model: transformer's DistilBertModel\n",
    "- Metric: Classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base line model metric_name='accuracy': perf=0.9179999828338623\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"bbc\" \n",
    "train_count, valid_count, test_count = 1000, 100, 500\n",
    "noise_rate = 0.1\n",
    "noise_kwargs = {'noise_rate': noise_rate}\n",
    "model_name = \"BertClassifier\"\n",
    "metric_name = \"accuracy\"\n",
    "train_kwargs = {\"epochs\": 2, \"batch_size\": 50}\n",
    "device = torch.device('cuda')\n",
    "\n",
    "exper_med = ExperimentMediator.model_factory_setup(\n",
    "    dataset_name=dataset_name,\n",
    "    cache_dir=\"../data_files/\",  \n",
    "    force_download=False,\n",
    "    train_count=train_count,\n",
    "    valid_count=valid_count,\n",
    "    test_count=test_count,\n",
    "    add_noise=mix_labels,\n",
    "    noise_kwargs=noise_kwargs,\n",
    "    train_kwargs=train_kwargs,\n",
    "    device=device,\n",
    "    model_name=model_name,\n",
    "    metric_name=metric_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 2] Compute data values\n",
    "`opendataval` provides various state-of-the-art data valuation algorithms. `ExperimentMediator.compute_data_values()` computes data values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_evaluators = [ \n",
    "    RandomEvaluator(),\n",
    "#     LeaveOneOut(), # leave one out ## slow\n",
    "    InfluenceSubsample(num_models=10), # influence function\n",
    "#     DVRL(rl_epochs=10), # Data valuation using Reinforcement Learning ## inappropriate\n",
    "#     KNNShapley(k_neighbors=valid_count), # KNN-Shapley ## inappropriate\n",
    "#     DataShapley(gr_threshold=1.05, mc_epochs=300, cache_name=f\"cached\"), # Data-Shapley ## slow\n",
    "#     BetaShapley(gr_threshold=1.05, mc_epochs=300, cache_name=f\"cached\"), # Beta-Shapley ## slow\n",
    "    DataBanzhaf(num_models=10), # Data-Banzhaf\n",
    "    AME(num_models=10), # Average Marginal Effects\n",
    "    DataOob(num_models=10) # Data-OOB\n",
    "#     LavaEvaluator(),\n",
    "#     RobustVolumeShapley(mc_epochs=300)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time RandomEvaluator(): 0:00:00.026117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:16<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time InfluenceSubsample(num_models=10): 0:00:16.937929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:12<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time DataBanzhaf(num_models=10): 0:00:12.857943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:06<00:00,  1.62it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:10<00:00,  1.04s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:14<00:00,  1.45s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:19<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time AME(num_models=10): 0:00:50.578566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:27<00:00,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time DataOob(num_models=10): 0:00:27.150970\n",
      "CPU times: user 1min 39s, sys: 7.2 s, total: 1min 46s\n",
      "Wall time: 1min 47s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# compute data values.\n",
    "## Training multiple DistilBERT models is extremely slow. We recommend using embeddings.\n",
    "exper_med = exper_med.compute_data_values(data_evaluators=data_evaluators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 3] Store data values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../tmp/bbc_noise_rate=0.1/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from opendataval.experiment.exper_methods import save_dataval\n",
    "\n",
    "# Saving the results\n",
    "output_dir = f\"../tmp/{dataset_name}_{noise_rate=}/\"\n",
    "exper_med.set_output_directory(output_dir)\n",
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indices</th>\n",
       "      <th>data_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomEvaluator()</th>\n",
       "      <td>2106</td>\n",
       "      <td>0.562118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomEvaluator()</th>\n",
       "      <td>1300</td>\n",
       "      <td>0.831894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomEvaluator()</th>\n",
       "      <td>1235</td>\n",
       "      <td>0.541294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomEvaluator()</th>\n",
       "      <td>1474</td>\n",
       "      <td>0.052256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomEvaluator()</th>\n",
       "      <td>3</td>\n",
       "      <td>0.827014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DataOob(num_models=10)</th>\n",
       "      <td>1915</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DataOob(num_models=10)</th>\n",
       "      <td>781</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DataOob(num_models=10)</th>\n",
       "      <td>2203</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DataOob(num_models=10)</th>\n",
       "      <td>1940</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DataOob(num_models=10)</th>\n",
       "      <td>1562</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       indices data_values\n",
       "RandomEvaluator()         2106    0.562118\n",
       "RandomEvaluator()         1300    0.831894\n",
       "RandomEvaluator()         1235    0.541294\n",
       "RandomEvaluator()         1474    0.052256\n",
       "RandomEvaluator()            3    0.827014\n",
       "...                        ...         ...\n",
       "DataOob(num_models=10)    1915         1.0\n",
       "DataOob(num_models=10)     781         0.0\n",
       "DataOob(num_models=10)    2203         1.0\n",
       "DataOob(num_models=10)    1940         1.0\n",
       "DataOob(num_models=10)    1562         0.8\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exper_med.evaluate(save_dataval, save_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
