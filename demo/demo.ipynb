{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo of current progress with Open Data Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from opendataval.util import set_random_state\n",
    "device = torch.device(\"cpu\")\n",
    "random_state = set_random_state(10)\n",
    "date = datetime.now().strftime(\"%m-%d_%H:%M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from opendataval.dataloader import DataFetcher, mix_labels\n",
    "\n",
    "dataset_name = \"iris\"\n",
    "noise_rate = .1\n",
    "\n",
    "# Equivalent arguments\n",
    "fetcher = (\n",
    "    DataFetcher(dataset_name, \"../data_files/\", False, random_state)\n",
    "    .split_dataset_by_count(80, 30, 10)\n",
    "    .noisify(mix_labels, noise_rate=noise_rate)\n",
    ")\n",
    "num_points = fetcher.num_points\n",
    "covar_dim = fetcher.covar_dim[0]\n",
    "label_dim = fetcher.label_dim[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the models and default arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from opendataval.model import ClassifierSkLearnWrapper, ClassifierUnweightedSkLearnWrapper, RegressionSkLearnWrapper\n",
    "from opendataval.model.logistic_regression import LogisticRegression as LR\n",
    "from opendataval.model.mlp import ClassifierMLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    # Wrappers for sklearn modles, makes the api more cohesive\n",
    "    'sklogreg': ClassifierSkLearnWrapper(LogisticRegression(), label_dim),\n",
    "    LogisticRegression: LR(covar_dim, label_dim).to(device),\n",
    "    'mlp': ClassifierMLP(covar_dim, label_dim, layers=3, hidden_dim=15).to(device),\n",
    "    'skknn': ClassifierUnweightedSkLearnWrapper(KNeighborsClassifier(label_dim), label_dim)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting your metrics and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"mlp\"\n",
    "metric_name = \"accuracy\"\n",
    "train_kwargs = {\"epochs\": 10, \"batch_size\": 20} if model_name in (\"mlp\", \"logreg\") else {}\n",
    "pred_model = models[model_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base line model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from opendataval.experiment.api import metrics_dict\n",
    "model = pred_model.clone()\n",
    "x_train, y_train, *_, x_test, y_test = fetcher.datapoints\n",
    "model.fit(x_train, y_train, **train_kwargs)\n",
    "metric = metrics_dict[metric_name]\n",
    "\n",
    "metric(y_test, model.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Evaluators present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from opendataval.dataval.influence import InfluenceFunctionEval\n",
    "from opendataval.dataval.dvrl import DVRL\n",
    "from opendataval.dataval.margcontrib import LeaveOneOut\n",
    "from opendataval.dataval.oob import DataOob\n",
    "from opendataval.dataval.knnshap import KNNShapley\n",
    "from opendataval.dataval.margcontrib import DataShapley\n",
    "from opendataval.dataval.margcontrib import BetaShapley\n",
    "from opendataval.dataval.margcontrib.banzhaf import DataBanzhaf, DataBanzhafMargContrib\n",
    "from opendataval.dataval.ame import BaggingEvaluator, AME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dummy_eval = [  # Used for quick testing and run throughs\n",
    "    InfluenceFunctionEval(10, random_state=random_state),\n",
    "    DataOob(10, random_state=random_state),\n",
    "    DVRL(10, rl_epochs=10, random_state=random_state),\n",
    "    LeaveOneOut(random_state=random_state),\n",
    "    AME(10, random_state=random_state),\n",
    "    DataBanzhaf(num_models=10, random_state=random_state),\n",
    "    DataBanzhafMargContrib(99, max_mc_epochs=2, models_per_iteration=1, cache_name=\"cache_dummy\", random_state=random_state),\n",
    "    BetaShapley(99, max_mc_epochs=2, models_per_iteration=1, cache_name=\"cache_dummy\", random_state=random_state),\n",
    "    DataShapley(cache_name=\"cache_dummy\", random_state=random_state),\n",
    "    DataShapley(99, max_mc_epochs=2, models_per_iteration=1, cache_name=\"cache_preset_other\", random_state=random_state),\n",
    "]\n",
    "\n",
    "data_evaluators = [  # actual run through of experiments, will take long time\n",
    "    InfluenceFunctionEval(2000, random_state=random_state),\n",
    "    DataOob(random_state=random_state),\n",
    "    DVRL(rl_epochs=2000, random_state=random_state),\n",
    "    LeaveOneOut(random_state=random_state),\n",
    "    AME(random_state=random_state),\n",
    "    DataBanzhaf(10000, random_state=random_state),\n",
    "    DataBanzhafMargContrib(gr_threshold=1.05, mc_epochs=500, cache_name=\"cached\", random_state=random_state),\n",
    "    BetaShapley(gr_threshold=1.05, mc_epochs=500, cache_name=\"cached\", random_state=random_state),\n",
    "    DataShapley(gr_threshold=1.05, mc_epochs=500, cache_name=\"cached\", random_state=random_state),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the Evaluator Mediator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from opendataval.experiment import ExperimentMediator\n",
    "exper_med = ExperimentMediator(fetcher, pred_model, train_kwargs, metric_name).compute_data_values(dummy_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting and getting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from opendataval.experiment.exper_methods import (\n",
    "    discover_corrupted_sample,\n",
    "    noisy_detection,\n",
    "    remove_high_low,\n",
    "    increasing_bin_removal,\n",
    "    save_dataval\n",
    ")\n",
    "\n",
    "# Saving the results\n",
    "output_dir = f\"../tmp/{dataset_name}_{noise_rate=}/{date}/\"\n",
    "exper_med.set_output_directory(output_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discover corrupted sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 15))\n",
    "df_resp, fig = exper_med.plot(discover_corrupted_sample, fig, col=2, save_output=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noisy sample F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exper_med.evaluate(noisy_detection, save_output=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removes high/low and evaluates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 15))\n",
    "df_resp, fig = exper_med.plot(remove_high_low, fig, include_train=True, col=2, save_output=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Increasing Bin Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 15))\n",
    "df_resp, fig = exper_med.plot(increasing_bin_removal, fig, include_train=True, col=2, save_output=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saves data values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exper_med.evaluate(save_dataval, save_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opendataval.util import load_mediator_output\n",
    "load_mediator_output(f\"{output_dir}/discover_corrupted_sample.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fresh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a30792999e96d101ca76d9a040890fe347a625eabba526b17f36b2f64aabff3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
