{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Demo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up global variables and random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "from opendataval.util import set_random_state\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "random_state = set_random_state(10)\n",
    "date = datetime.now().strftime(\"%m-%d_%H:%M\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opendataval.dataloader.noisify import add_gauss_noise, mix_labels\n",
    "regression_datasets = [\"diabetes\", \"linnerud\"]\n",
    "regression_models = ['mlpregress', 'sklinreg']\n",
    "\n",
    "dataset_name = regression_datasets[1]\n",
    "train_count, valid_count, test_count = 100, 50, 50\n",
    "add_noise_func = add_gauss_noise\n",
    "noise_rate = 0.1\n",
    "noise_kwargs = { 'noise_rate': noise_rate }\n",
    "\n",
    "\n",
    "model_name = regression_models[1]\n",
    "train_kwargs = {\"epochs\": 20, \"batch_size\": 50} if \"sk\" not in model_name else {}\n",
    "metric_name = \"mse\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get ExperimentMediator without specifying DataEvaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opendataval.experiment import ExperimentMediator\n",
    "\n",
    "exper_med = ExperimentMediator.model_factory_setup(\n",
    "    dataset_name=dataset_name,\n",
    "    cache_dir=\"../data_files/\",  # Since move inside demo directory\n",
    "    force_download=False,\n",
    "    train_count=train_count,\n",
    "    valid_count=valid_count,\n",
    "    test_count=test_count,\n",
    "    add_noise_func=add_noise_func,\n",
    "    noise_kwargs=noise_kwargs,\n",
    "    random_state=random_state,\n",
    "    model_name=model_name,\n",
    "    device=device,\n",
    "    train_kwargs=train_kwargs,\n",
    "    metric_name=metric_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Evaluators"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lots of imports for the many Data Evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opendataval.dataval.ame import AME\n",
    "from opendataval.dataval.dvrl import DVRL\n",
    "from opendataval.dataval.influence import InfluenceFunctionEval\n",
    "from opendataval.dataval.knnshap import KNNShapley\n",
    "from opendataval.dataval.oob import DataOob\n",
    "from opendataval.dataval.margcontrib import LeaveOneOut\n",
    "from opendataval.dataval.margcontrib import BetaShapley, DataShapley\n",
    "from opendataval.dataval.margcontrib.banzhaf import DataBanzhaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up a series of data evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_evaluators = [\n",
    "    AME(num_models=1500, random_state=random_state),\n",
    "    DataOob(2000, random_state=random_state),  # 1000 samples\n",
    "    DVRL(rl_epochs=4000, random_state=random_state, device=device),  # RL requires torch device\n",
    "    InfluenceFunctionEval(5000, random_state=random_state),\n",
    "    DataBanzhaf(5000, random_state=random_state),\n",
    "    BetaShapley(gr_threshold=1.05, min_samples=500, cache_name=\"cached\", random_state=random_state),\n",
    "    DataShapley(gr_threshold=1.05, min_samples=500, cache_name=\"cached\", random_state=random_state),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exper_med = exper_med.compute_data_values(data_evaluators=data_evaluators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running experiments on the data values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opendataval.experiment.exper_methods import (\n",
    "    discover_corrupted_sample,\n",
    "    noisy_detection,\n",
    "    remove_high_low,\n",
    "    increasing_bin_removal,\n",
    "    save_dataval\n",
    ")\n",
    "\n",
    "# Saving the results\n",
    "output_dir = f\"../tmp/{dataset_name}_{noise_rate=}/{date}/\"\n",
    "exper_med.set_output_directory(output_dir)\n",
    "output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discover corrupted sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 15))\n",
    "df_resp, fig = exper_med.plot(discover_corrupted_sample, fig, col=2, save_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noisy detection F1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exper_med.evaluate(noisy_detection, save_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing high values and low values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 15))\n",
    "df_resp, fig = exper_med.plot(remove_high_low, fig, include_train=True, col=2, save_output=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing bin removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 15))\n",
    "df_resp, fig = exper_med.plot(increasing_bin_removal, fig, include_train=True, col=2, save_output=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save data values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exper_med.evaluate(save_dataval, save_output=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fresher",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
