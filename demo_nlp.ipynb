{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Demo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up global variables and random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial random seed is: 10.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "from dataoob.util import set_random_state\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "random_state = set_random_state(10)\n",
    "date = datetime.now().strftime(\"%m-%d_%H:%M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up data loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pick Noise rate and data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataoob.dataloader.datasets.nlpsets  # Must import as NLP data sets aren't imported automatically\n",
    "nlp_datasets = [\"bbc\", \"imdb\"]\n",
    "dataset_name = nlp_datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataoob.dataloader import DataFetcher\n",
    "\n",
    "# Equivalent arguments\n",
    "fetcher = (\n",
    "    DataFetcher(dataset_name, False, random_state)\n",
    "    .split_dataset(100, 50, 50)  # No noise functions for NLP yet\n",
    ")\n",
    "num_points = len(fetcher.x_train)\n",
    "label_dim = (1,) if fetcher.y_train.ndim == 1 else fetcher.y_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinjiang/opt/anaconda3/envs/fresher/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import examples of appropriate Models\n",
    "# TODO think of more Regression models\n",
    "from dataoob.model.bert import BertClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "catalog = {\n",
    "    # Only one NLP model so far\n",
    "    'bert': BertClassifier(\"distilbert-base-uncased\", *label_dim).to(device=device),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose a model from the catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert\"\n",
    "metric_name = \"accuracy\"\n",
    "train_kwargs = {\"epochs\": 2, \"batch_size\": 50} \n",
    "\n",
    "pred_model = catalog[model_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base line performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.07s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9599999785423279"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataoob.evaluator.api import metrics_dict\n",
    "model = pred_model.clone()\n",
    "x_train, y_train, *_, x_test, y_test = fetcher.datapoints\n",
    "\n",
    "model.fit(x_train, y_train, **train_kwargs)\n",
    "metric = metrics_dict[metric_name]\n",
    "\n",
    "metric(y_test, model.predict(x_test).cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Evaluators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lots of imoprts for the many Data Evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataoob.dataval.ame import AME\n",
    "from dataoob.dataval.dvrl import DVRL\n",
    "from dataoob.dataval.influence import InfluenceFunctionEval\n",
    "from dataoob.dataval.knnshap import KNNShapley\n",
    "from dataoob.dataval.oob import DataOob\n",
    "from dataoob.dataval import LeaveOneOut\n",
    "from dataoob.dataval import BetaShapley, DataShapley\n",
    "from dataoob.dataval import DataBanzhaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up a series of data evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_evaluators = [\n",
    "    AME(num_models=1500, random_state=random_state),\n",
    "    DataOob(random_state=random_state),  # 1000 samples\n",
    "    # DVRL(rl_epochs=3000, random_state=random_state, device=device),  # DVRL requires tensor inputs\n",
    "    LeaveOneOut(random_state=random_state),\n",
    "    InfluenceFunctionEval(5000, random_state=random_state),\n",
    "    DataBanzhaf(5000, random_state=random_state),\n",
    "    BetaShapley(gr_threshold=1.05, min_samples=500, cache_name=\"cached\", random_state=random_state),\n",
    "    DataShapley(gr_threshold=1.05, min_samples=500, cache_name=\"cached\", random_state=random_state),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.15it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.87it/s]it]\n",
      "100%|██████████| 2/2 [00:00<00:00,  5.13it/s]it]\n",
      "100%|██████████| 2/2 [00:00<00:00,  5.02it/s]/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.86it/s]/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.98it/s]/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.92it/s]/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 12.06it/s]/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 11.76it/s]/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 12.14it/s]/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 10.14it/s]t/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  9.89it/s]t/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 11.92it/s]t/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.93it/s]t/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 11.42it/s]t/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.17it/s]t/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 12.27it/s]t/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.24it/s]t/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 10.86it/s]t/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.82it/s]t/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 11.76it/s]t/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 11.87it/s]t/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  9.42it/s]t/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  8.59it/s]t/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  9.19it/s]t/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  5.03it/s]t/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.42it/s]t/s]\n",
      " 50%|█████     | 1/2 [00:00<00:00,  5.88it/s]t/s]\n",
      "  2%|▏         | 27/1500 [00:15<13:57,  1.76it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdataoob\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mevaluator\u001b[39;00m \u001b[39mimport\u001b[39;00m ExperimentMediator\n\u001b[0;32m----> 2\u001b[0m exper_med \u001b[39m=\u001b[39m ExperimentMediator(\n\u001b[1;32m      3\u001b[0m     fetcher\u001b[39m=\u001b[39;49mfetcher,\n\u001b[1;32m      4\u001b[0m     data_evaluators\u001b[39m=\u001b[39;49mdata_evaluators,\n\u001b[1;32m      5\u001b[0m     pred_model\u001b[39m=\u001b[39;49mpred_model,\n\u001b[1;32m      6\u001b[0m     train_kwargs\u001b[39m=\u001b[39;49mtrain_kwargs,\n\u001b[1;32m      7\u001b[0m     metric_name\u001b[39m=\u001b[39;49mmetric_name\n\u001b[1;32m      8\u001b[0m )\n",
      "File \u001b[0;32m~/repo/opendataval/dataoob/evaluator/api.py:103\u001b[0m, in \u001b[0;36mExperimentMediator.__init__\u001b[0;34m(self, fetcher, data_evaluators, pred_model, train_kwargs, metric_name)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39mfor\u001b[39;00m data_val \u001b[39min\u001b[39;00m data_evaluators:\n\u001b[1;32m    100\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_evaluators\u001b[39m.\u001b[39mappend(\n\u001b[0;32m--> 103\u001b[0m             data_val\u001b[39m.\u001b[39;49minput_model_metric(pred_model, metrics_dict[metric_name])\n\u001b[1;32m    104\u001b[0m             \u001b[39m.\u001b[39;49minput_fetcher(fetcher)\n\u001b[1;32m    105\u001b[0m             \u001b[39m.\u001b[39;49mtrain_data_values(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_kwargs)\n\u001b[1;32m    106\u001b[0m         )\n\u001b[1;32m    108\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m ex:\n\u001b[1;32m    109\u001b[0m         \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n",
      "File \u001b[0;32m~/repo/opendataval/dataoob/dataval/ame/ame.py:51\u001b[0m, in \u001b[0;36mAME.train_data_values\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m subsets, performance \u001b[39m=\u001b[39m [], []\n\u001b[1;32m     49\u001b[0m \u001b[39mfor\u001b[39;00m proportion \u001b[39min\u001b[39;00m [\u001b[39m0.2\u001b[39m, \u001b[39m0.4\u001b[39m, \u001b[39m0.6\u001b[39m, \u001b[39m0.8\u001b[39m]:\n\u001b[1;32m     50\u001b[0m     sub, perf \u001b[39m=\u001b[39m (\n\u001b[0;32m---> 51\u001b[0m         BaggingEvaluator(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_models, proportion, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state)\n\u001b[1;32m     52\u001b[0m         \u001b[39m.\u001b[39;49minput_model_metric(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpred_model, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmetric)\n\u001b[1;32m     53\u001b[0m         \u001b[39m.\u001b[39;49minput_data(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx_train, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my_train, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx_valid, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my_valid)\n\u001b[1;32m     54\u001b[0m         \u001b[39m.\u001b[39;49mtrain_data_values(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     55\u001b[0m         \u001b[39m.\u001b[39mget_subset_perf()\n\u001b[1;32m     56\u001b[0m     )\n\u001b[1;32m     58\u001b[0m     subsets\u001b[39m.\u001b[39mappend(sub)\n\u001b[1;32m     59\u001b[0m     performance\u001b[39m.\u001b[39mappend(perf)\n",
      "File \u001b[0;32m~/repo/opendataval/dataoob/dataval/ame/ame.py:167\u001b[0m, in \u001b[0;36mBaggingEvaluator.train_data_values\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    166\u001b[0m curr_model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpred_model\u001b[39m.\u001b[39mclone()\n\u001b[0;32m--> 167\u001b[0m curr_model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    168\u001b[0m     Subset(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx_train, indices\u001b[39m=\u001b[39;49msubset),\n\u001b[1;32m    169\u001b[0m     Subset(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my_train, indices\u001b[39m=\u001b[39;49msubset),\n\u001b[1;32m    170\u001b[0m     \u001b[39m*\u001b[39;49margs,\n\u001b[1;32m    171\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    172\u001b[0m )\n\u001b[1;32m    173\u001b[0m y_valid_hat \u001b[39m=\u001b[39m curr_model\u001b[39m.\u001b[39mpredict(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx_valid)\n\u001b[1;32m    175\u001b[0m curr_perf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_valid, y_valid_hat)\n",
      "File \u001b[0;32m~/repo/opendataval/dataoob/model/bert.py:215\u001b[0m, in \u001b[0;36mBertClassifier.fit\u001b[0;34m(self, x_train, y_train, sample_weight, batch_size, epochs)\u001b[0m\n\u001b[1;32m    212\u001b[0m             loss \u001b[39m=\u001b[39m criterion(y_hat, y_batch, reduction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    214\u001b[0m         loss\u001b[39m.\u001b[39mbackward(retain_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 215\u001b[0m         optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m    216\u001b[0m         scheduler\u001b[39m.\u001b[39mstep()\n\u001b[1;32m    218\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fresher/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:69\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m instance\u001b[39m.\u001b[39m_step_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     68\u001b[0m wrapped \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__get__\u001b[39m(instance, \u001b[39mcls\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fresher/lib/python3.11/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fresher/lib/python3.11/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fresher/lib/python3.11/site-packages/torch/optim/adamw.py:171\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    158\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m\"\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    160\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[1;32m    161\u001b[0m         group,\n\u001b[1;32m    162\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    168\u001b[0m         state_steps,\n\u001b[1;32m    169\u001b[0m     )\n\u001b[0;32m--> 171\u001b[0m     adamw(\n\u001b[1;32m    172\u001b[0m         params_with_grad,\n\u001b[1;32m    173\u001b[0m         grads,\n\u001b[1;32m    174\u001b[0m         exp_avgs,\n\u001b[1;32m    175\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    176\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    177\u001b[0m         state_steps,\n\u001b[1;32m    178\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    179\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    180\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    181\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    182\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    183\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    184\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    185\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    186\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    187\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    188\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    189\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    190\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    191\u001b[0m     )\n\u001b[1;32m    193\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fresher/lib/python3.11/site-packages/torch/optim/adamw.py:321\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 321\u001b[0m func(\n\u001b[1;32m    322\u001b[0m     params,\n\u001b[1;32m    323\u001b[0m     grads,\n\u001b[1;32m    324\u001b[0m     exp_avgs,\n\u001b[1;32m    325\u001b[0m     exp_avg_sqs,\n\u001b[1;32m    326\u001b[0m     max_exp_avg_sqs,\n\u001b[1;32m    327\u001b[0m     state_steps,\n\u001b[1;32m    328\u001b[0m     amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    329\u001b[0m     beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    330\u001b[0m     beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    331\u001b[0m     lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    332\u001b[0m     weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    333\u001b[0m     eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    334\u001b[0m     maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    335\u001b[0m     capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    336\u001b[0m     differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    337\u001b[0m     grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    338\u001b[0m     found_inf\u001b[39m=\u001b[39;49mfound_inf,\n\u001b[1;32m    339\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fresher/lib/python3.11/site-packages/torch/optim/adamw.py:442\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    440\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[0;32m--> 442\u001b[0m param\u001b[39m.\u001b[39;49maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from dataoob.evaluator import ExperimentMediator\n",
    "exper_med = ExperimentMediator(\n",
    "    fetcher=fetcher,\n",
    "    data_evaluators=data_evaluators,\n",
    "    pred_model=pred_model,\n",
    "    train_kwargs=train_kwargs,\n",
    "    metric_name=metric_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running experiments on the data values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataoob.evaluator.exper_methods import remove_high_low, increasing_bin_removal\n",
    "\n",
    "# Saving the results\n",
    "import os\n",
    "output_dir = f\"tmp/{dataset_name}/{date}/\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing high values and low values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 15))\n",
    "df_resp, fig = exper_med.plot(remove_high_low, include_train=True, col=2)\n",
    "df_resp.to_csv(f\"{output_dir}/remove_high_low.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing bin removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 15))\n",
    "df_resp, fig = exper_med.plot(increasing_bin_removal, include_train=True, col=2)\n",
    "df_resp.to_csv(f\"{output_dir}/increasing_bin_removal.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fresher",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
