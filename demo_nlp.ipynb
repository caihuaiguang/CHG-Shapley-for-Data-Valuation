{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Demo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up global variables and random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "from dataoob.util import set_random_state\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "random_state = set_random_state(10)\n",
    "date = datetime.now().strftime(\"%m-%d_%H:%M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up data loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pick Noise rate and data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataoob.dataloader.datasets.nlpsets  # Must import as NLP data sets aren't imported automatically\n",
    "nlp_datasets = [\"bbc\", \"imdb\"]\n",
    "dataset_name = nlp_datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataoob.dataloader import DataFetcher\n",
    "\n",
    "# Equivalent arguments\n",
    "fetcher = (\n",
    "    DataFetcher(dataset_name, False, random_state)\n",
    "    .split_dataset(100, 50, 50)  # No noise functions for NLP yet\n",
    ")\n",
    "num_points = len(fetcher.x_train)\n",
    "label_dim = (1,) if fetcher.y_train.ndim == 1 else fetcher.y_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import examples of appropriate Models\n",
    "# TODO think of more Regression models\n",
    "from dataoob.model.bert import BertClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = {\n",
    "    # Only one NLP model so far\n",
    "    'bert': BertClassifier(\"distilbert-base-uncased\", *label_dim).to(device),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose a model from the catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert\"\n",
    "metric_name = \"accuracy\"\n",
    "train_kwargs = train_kwargs = {\"epochs\": 50, \"batch_size\": 20} if model_name in (\"ann\", \"logreg\") else {}\n",
    "\n",
    "pred_model = catalog[model_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base line performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataoob.evaluator.api import metrics_dict\n",
    "model = pred_model.clone()\n",
    "x_train, y_train, x_valid, y_valid, *_ = fetcher.datapoints\n",
    "model.fit(x_train, y_train, **train_kwargs)\n",
    "metric = metrics_dict[metric_name]\n",
    "\n",
    "metric(y_valid, model.predict(x_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Evaluators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lots of imoprts for the many Data Evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataoob.dataval.ame import AME\n",
    "from dataoob.dataval.dvrl import DVRL\n",
    "from dataoob.dataval.influence import InfluenceFunctionEval\n",
    "from dataoob.dataval.knnshap import KNNShapley\n",
    "from dataoob.dataval.oob import DataOob\n",
    "from dataoob.dataval.shap import LeaveOneOut\n",
    "from dataoob.dataval.shap import BetaShapley, DataShapley\n",
    "from dataoob.dataval.shap.banzhaf import DataBanzhaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up a series of data evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_evaluators = [\n",
    "    AME(num_models=1500, random_state=random_state),\n",
    "    DataOob(random_state=random_state),  # 1000 samples\n",
    "    # DVRL(rl_epochs=3000, random_state=random_state, device=device),  # DVRL requires tensor inputs\n",
    "    InfluenceFunctionEval(5000, random_state=random_state),\n",
    "    DataBanzhaf(5000, random_state=random_state),\n",
    "    BetaShapley(gr_threshold=1.05, min_samples=500, cache_name=\"cached\", random_state=random_state),\n",
    "    DataShapley(gr_threshold=1.05, min_samples=500, cache_name=\"cached\", random_state=random_state),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataoob.evaluator import ExperimentMediator, presets\n",
    "exper_med = ExperimentMediator(\n",
    "    fetcher=fetcher,\n",
    "    data_evaluators=presets.dummy_evaluators,\n",
    "    pred_model=pred_model,\n",
    "    train_kwargs=train_kwargs,\n",
    "    metric_name=metric_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running experiments on the data values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataoob.evaluator.exper_methods import remove_high_low, point_removal\n",
    "\n",
    "# Saving the results\n",
    "import os\n",
    "output_dir = f\"tmp/{dataset_name}/{date}/\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing high values and low values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 15))\n",
    "df_resp, fig = exper_med.plot(remove_high_low, include_train=True, col=2)\n",
    "df_resp.to_csv(f\"{output_dir}/remove_high_low.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove descending values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 15))\n",
    "df_resp, fig = exper_med.plot(point_removal, include_train=True, col=2, percentile=.05, order=\"descending\")\n",
    "df_resp.to_csv(f\"{output_dir}/descending_remove.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove ascending values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 15))\n",
    "df_resp, fig = exper_med.plot(point_removal, include_train=True, col=2, order=\"ascending\")\n",
    "df_resp.to_csv(f\"{output_dir}/ascending_remove.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fresher",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
