{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo of current progress with Dataoob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinjiang/opt/anaconda3/envs/data-oob/lib/python3.11/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import sklearn.metrics as metrics\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataoob.dataloader import data_loader\n",
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "train_count = 1000\n",
    "valid_count = 400\n",
    "test_count = 100\n",
    "\n",
    "(x_train, y_train), (x_valid, y_valid), (x_test, y_test) = data_loader.DataLoader(\n",
    "    'adult', False, train_count, valid_count, test_count, categorical=True, device=device, \n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the models and default arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from dataoob.model import ann, logistic_regression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from dataoob.model import ClassifierSkLearnWrapper, ClassifierUnweightedSkLearnWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    # Wrappers for sklearn modles, makes the api more cohesive\n",
    "    'sklogreg': ClassifierSkLearnWrapper(LogisticRegression(), device=device),\n",
    "    'logreg': logistic_regression.LogisticRegression(x_train.shape[1]),\n",
    "    'ann': ann.ANN(2),\n",
    "    'knn': ClassifierUnweightedSkLearnWrapper(KNeighborsClassifier(2), device=device)\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc =  lambda a, b: metrics.roc_auc_score(a.detach().cpu(), b.detach().cpu())\n",
    "acc = lambda a, b: metrics.accuracy_score(torch.argmax(a).detach().cpu(), torch.argmax(b).detach().cpu())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting your metrics and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models['sklogreg']\n",
    "metric = roc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DVRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataoob.dataval.dvrl.dvrl import DVRL\n",
    "dvrl = DVRL(\n",
    "    pred_model=model,\n",
    "    metric=metric,\n",
    "    x_dim=x_train.shape[1],\n",
    "    y_dim=2,\n",
    "    hidden_dim=100,\n",
    "    layer_number=5,\n",
    "    comb_dim=10,\n",
    "    act_fn=torch.nn.ReLU(),\n",
    "    device=device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ConcatDataset.__init__() takes 2 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m dvrl\u001b[39m.\u001b[39minput_data(x_train, y_train, x_valid, y_valid)\n\u001b[0;32m----> 3\u001b[0m dvrl\u001b[39m.\u001b[39;49mtrain_data_values(batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m, rl_epochs\u001b[39m=\u001b[39;49m\u001b[39m2000\u001b[39;49m)\n\u001b[1;32m      4\u001b[0m e \u001b[39m=\u001b[39m dvrl\u001b[39m.\u001b[39mevaluate_data_values(x_train, y_train)\n",
      "File \u001b[0;32m~/repo/data-oob/dataoob/dataval/dvrl/dvrl.py:181\u001b[0m, in \u001b[0;36mDVRL.train_data_values\u001b[0;34m(self, pre_train_pred, batch_size, rl_epochs, epochs, lr, threshold)\u001b[0m\n\u001b[1;32m    177\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalue_estimator\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlr)\n\u001b[1;32m    178\u001b[0m criterion \u001b[39m=\u001b[39m DveLoss(threshold\u001b[39m=\u001b[39mthreshold)\n\u001b[0;32m--> 181\u001b[0m dataset \u001b[39m=\u001b[39m ConcatDataset(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx_train, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my_train, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my_pred_diff)\n\u001b[1;32m    182\u001b[0m rs \u001b[39m=\u001b[39m RandomSampler(dataset, replacement\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, num_samples\u001b[39m=\u001b[39m(rl_epochs \u001b[39m*\u001b[39m batch_size))\n\u001b[1;32m    183\u001b[0m \u001b[39mfor\u001b[39;00m x_batch, y_batch, y_hat_batch \u001b[39min\u001b[39;00m tqdm\u001b[39m.\u001b[39mtqdm(DataLoader(dataset, sampler\u001b[39m=\u001b[39mrs, batch_size\u001b[39m=\u001b[39mbatch_size)):\n",
      "\u001b[0;31mTypeError\u001b[0m: ConcatDataset.__init__() takes 2 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "dvrl.input_data(x_train, y_train, x_valid, y_valid)\n",
    "\n",
    "dvrl.train_data_values(batch_size=128, rl_epochs=2000)\n",
    "e = dvrl.evaluate_data_values(x_train, y_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataoob.dataval.shap.shap import ShapEvaluator\n",
    "ShapEvaluator(\n",
    "    pred_model=model,\n",
    "    metric=metric,\n",
    "    GR_threshold=1.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-oob",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0c5d468402920c68d7cbbb0f04321ce29d469766a3681c96761f45e31914380d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
